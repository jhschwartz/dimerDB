import sys
import os
import pickle

configfn = 'config.yaml'  
configfile: configfn


sys.path.append(config['paths']['scripts'])
from simple_write import simple_write
from download_uniparc_fasta import download_fasta
from read_fasta import read_prot_from_fasta
from name_fasta import uniparc_fasta
from name_pdb import dimer2pdbs
from check_chains_contact import check_chains_contact

sys.path.append(config['paths']['scripts'])
from name_pdb import name_pdb_file

sys.path.append(config['paths']['labels_loc'])
import labels as label_funcs





out_base_path_homo = config['paths']['intermediates_homodimer_filtering']

homodimers_pkl = config['intermediate_data_files']['sub1_all_homodimers_pkl']
uniparc2others_pkl = config['intermediate_data_files']['sub1_uniparc2others_pkl']


with open(homodimers_pkl, 'rb') as f:
    homodimers_data = pickle.load(f)
    samples_homo = homodimers_data.keys()


divs = [s[-2:] for s in samples_homo]


with open(uniparc2others_pkl, 'rb') as f:
    uniparc2others = pickle.load(f)




# len -> afdb -> contact 
localrules: all

rule all:
    input:
        merged_pklfile_homo = config['intermediate_data_files']['sub2_homo_prefiltered_pkl'],
        merged_uniparc2af_homo = config['intermediate_data_files']['sub2_uniparc2af_pkl_homo']
    output:
        done = config['snake_donefiles']['sub2_all_done']
    run:
        simple_write(output.done, 'success')



#####################################
############## ACTIONS ##############
# VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV #


def merge_pklfiles(infiles, outfile):
    data = {}
    for pklfile in infiles:    
        with open(pklfile, 'rb') as f:
            pklfile_data = pickle.load(f)
            if is_instance(pklfile_data, dict):
                data = {**data, **pklfile_data} # merge dicts data and the read dict from pkl
    with open(outfile, 'wb') as f:
        pickle.dump(data, f)


def make_uniparc2afinfo(afinfo_files, names, outfile):
    uniparc2af = {}
    for afinfo, uniparc in zip(afinfo_files, names):
        with open(afinfo, 'r') as f:
            info = f.read().strip()
        if info != 'no':
            afname = info
            uniparc2af[uniparc] = afname
    with open(outfile, 'wb') as f:
        pickle.dump(uniparc2af, f)


def init_indiv_pkls(data, pklfiles):
    for uniparc, chain_pairs in data.items():
        pklfile = [yf for yf in pklfiles if uniparc in yf]
        if len(pklfile) != 1:
            raise ValueError(f'should find exactly one matching pkl filename for uniparc {uniparc} but found {len(pklfile)}')
        pklfile = pklfile[0]
        if os.path.exists(pklfile):
            continue
        unit_data = {
            uniparc: chain_pairs
        }
        with open(pklfile, 'wb') as f:
            pickle.dump(unit_data, f)


def write_yes_if_func(outfile, func, *args):
    if func(*args):
        simple_write(outfile, 'yes')
    



def match_seq_to_afdb(query_fasta, afdb_fasta):
    _, target_seq = next(read_prot_from_fasta(query_fasta))
    for header, seq in read_prot_from_fasta(afdb_fasta):
        if seq == target_seq:
            name = re.findall('>AFDB:(.*?)\s', header)[0]
            return name
    return None


def filter_only_contacting_structures(uniparc, inpkl):
    with open(inpkl, 'rb') as f:
        data = pickle.load(f)
    dimers = data[uniparc]
    dimers_in_contact = []
    
    lib_path = config['paths']['lib']
    dist_thresh = config['database_settings']['dimer_define_contact_distance_threshold_angstroms']
    count_thresh = config['database_settings']['dimer_define_contact_min_total_contacting_pairs']

    for d in dimers:
        pdb1, pdb2 = dimer2pdbs(d, lib_path)
        if check_chains_contact(pdb1, pdb2, label_funcs, dist_thresh, count_thresh):
            dimers_in_contact.append(d)

    return dimers_in_contact



##########################################
############## HOMODIMER RULES ###########
# VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV #

localrules: download_xray_resolu

rule download_xray_resolu:
    output:
        resolu = config['paths']['resolu_file']
    shell:
        '''
        wget -O {output.resolu} https://files.wwpdb.org/pub/pdb/derived_data/index/resolu.idx;
        '''


rule init_indiv_pkls_homo: 
    output:
        pklfiles = expand(out_base_path_homo+'/{div}/{sample_homo}/initial.pkl', zip, div=divs, sample_homo=samples_homo)
    threads: 1
    resources:
       time = "48:00:00",
       mem_mb = "30000"
    run:
        init_indiv_pkls(data=homodimers_data, pklfiles=output.pklfiles)



'''
Ensures we move forward only with homodimers represented in AFDB.
  In a subdirectory for each homodimer, named by its corresponding uniparc id, and given
  a initial.pkl file that contains the uniparc2others_expanded_cleaned.pkl entry of the homdimer:
      - if a given homodimer is represented in AFDB, write the AFDB id to the resulting "afdb_match.info" file
      - otherwise, write "no afdb match" to the resulting "afdb_match.info" file
'''
rule prefilter_by_in_afdb_homo:
    input:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/initial.pkl'
    output:
        info = out_base_path_homo+'/{div}/{sample_homo}/afdb_match.info'
    threads: 1
    run:
        simple_write(output.info, 'no afdb match')
        afdb_fasta = config['paths']['afdb_fasta']
        fasta = uniparc_fasta(uniparc_id=wildcards.sample_homo, lib_path=config['paths']['lib'])
        af_name = match_seq_to_afdb(fasta, afdb_fasta)
        if af_name:
            simple_write(output.info, f'{af_name}')




'''                    
Ensures we move forward only with homodimers that are physically in contact, where contact is
defined by parameters in the pipeline config.yaml
  In the homodimer filtering subdirectory, and given the afdb matches (if they exist) in "afdb_match.info",
  and given the "initial.pkl" file:
    Depending on content of input "afdb_match.info"...
        1. 'no afdb match'
                --> write 'skipped because no afdb match' as string in output pkl
        2. <a string which is the id of an afdb match>
                --> perform filtration by physical contact, then write
                    contacting dimers as a list in the output pkl
      Note: the written list of dimers can be empty, i.e. [], if there is no incontact dimer upon checking.
'''
rule prefilter_by_physical_contact:
    input:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/initial.pkl',
        info = out_base_path_homo+'/{div}/{sample_homo}/afdb_match.info'
    output:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/incontact.pkl'
    threads: 1
    resources:
        mem_mb = "8000",
        time = "4:00:00"
    run:
        to_write = None

        with open(input.info, 'r') as f:
            afdb_no_match = f.read().strip() == 'no afdb match'
        if afdb_no_match:
            to_write = 'skipped because no afdb match'
        else:
            incontact = filter_only_contacting_structures(uniparc=wildcards.sample_homo, inpkl=input.pklfile)
            to_write = incontact

        with open(output.pklfile, 'wb') as f:
            pickle.dump(to_write, f)
        


'''
Ensures we move forward only with structurally non-redundant dimer structures for each homodimer sequence.
In the filitering directory for a uniparc homodimer sequence, and given "incontact.pkl":
    Three different actions:
        Depending on contents of input "incontact.pkl"...
        1. 'skipped because no afdb match' 
                --> write 'skipped because no afdb match' as string in output pkl
        2. []
                --> write 'skipped because no in contact dimers' as string in output pkl
        3. [<at least one dimer>]
                --> prune structural redudnancy, then write the resulting list to output pkl
                    according to the format below:

                        dict of one key
                            key is the uniparc ID
                            value is the nonredundant list of dimers
                            e.g.
                                { '<uniparc id>': [<dimer 1>, <dimer 2>, ...] }
'''
rule filter_by_redundancy:
    input:
        resolu = config['paths']['resolu_file'],
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/incontact.pkl'
    output:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/incontact_nonredundant.pkl'
    threads: 4
    resources:
        mem_mb = 5000,
        time = "4:00:00"
    params:
        prefer_xray = config['database_settings']['preference_xray_structures']
    run:
        to_write = None
        with open(input.pklfile, 'rb') as f:
            loaded = pickle.load(f)
        if loaded == 'skipped because no afdb match':
            to_write = 'skipped because no afdb match'
        elif loaded == {}:
            to_write = 'skipped because no in contact dimers'
        else:
            uniparc = list(loaded.keys())[0]
            structures = loaded[uniparc] 
            dimers = RedundantDimerStructures(dimer_tuples=structures, threshold=config['database_settings']['dimer_cluster_distance_threshold'], config=config)
            non_redundant_dimers = {}
            non_redundant_dimers[uniparc] = dimers.prune_redundancy(num_workers=threads, prefer_xray=params.prefer_xray)
            to_write = non_redundant_dimers
        
        with open(output.pklfile, 'wb') as f:
            pickle.dump(to_write, f)

            





'''
After all filtration steps, merges all 'incontact_nonredundant.pkl' files into one dict in a pkl,
skipping any 'incontact_nonredundant.pkl' that contain messages of skipped homodimers.
    This skipping is done in merge_pklfiles because only pklfiles that contain dicts are merged.
    The skip messages are all strings in 'incontact_nonredundant.pkl' files.
'''
rule merge_homo_data:
    input:
        pklfiles = expand(out_base_path_homo+'/{div}/{sample_homo}/incontact_nonredundant.pkl', zip, div=divs, sample_homo=samples_homo),
        afinfos = expand(out_base_path_homo+'/{div}/{sample_homo}/ok_afdb.info', zip, div=divs, sample_homo=samples_homo)
    output:
        merged_pklfile = config['intermediate_data_files']['sub2_homo_prefiltered_pkl'],
        merged_uniparc2af = config['intermediate_data_files']['sub2_uniparc2af_pkl_homo']
    threads: 1
    resources:
        mem_mb = 5000,
        time = '24:00:00'
    run:
        merge_pklfiles(infiles=input.pklfiles, outfile=output.merged_pklfile)
        make_uniparc2afinfo(afinfo_files=input.afinfos, names=samples_homo, outfile=output.merged_uniparc2af)


