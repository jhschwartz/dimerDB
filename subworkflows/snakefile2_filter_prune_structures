import sys
import os
import pickle

configfn = 'config.yaml'  
configfile: configfn


sys.path.append(config['paths']['scripts'])
from simple_write import simple_write
from download_uniparc_fasta import download_fasta
from read_fasta import read_prot_from_fasta
from name_pdb import dimer2pdbs
from check_chains_contact import check_chains_contact

sys.path.append(config['paths']['scripts'])
from name_pdb import name_pdb_file

sys.path.append(config['paths']['labels_loc'])
import labels as label_funcs





out_base_path_homo = config['paths']['intermediates_homodimer_filtering']

homodimers_pkl = config['intermediate_data_files']['sub1_all_homodimers_pkl']
uniparc2others_pkl = config['intermediate_data_files']['sub1_uniparc2others_pkl']


with open(homodimers_pkl, 'rb') as f:
    homodimers_data = pickle.load(f)
    samples_homo = homodimers_data.keys()


divs_homo = [s[-2:] for s in samples_homo]


with open(uniparc2others_pkl, 'rb') as f:
    uniparc2others = pickle.load(f)




# len -> afdb -> contact 
localrules: all

rule all:
    input:
        merged_pklfile_homo = config['intermediate_data_files']['sub2_homo_prefiltered_pkl'],
        merged_uniparc2af_homo = config['intermediate_data_files']['sub2_uniparc2af_pkl_homo']
    output:
        done = config['snake_donefiles']['sub2_all_done']
    run:
        simple_write(output.done, 'success')



#####################################
############## ACTIONS ##############
# VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV #


def merge_pklfiles(infiles, outfile):
    data = {}
    for pklfile in infiles:    
        with open(pklfile, 'rb') as f:
            data = {**data, **pickle.load(f)} # merge dicts data and the read dict from pkl
    with open(outfile, 'wb') as f:
        pickle.dump(data, f)


def make_uniparc2afinfo(afinfo_files, names, outfile):
    uniparc2af = {}
    for afinfo, uniparc in zip(afinfo_files, names):
        with open(afinfo, 'r') as f:
            info = f.read().strip()
        if info != 'no':
            afname = info
            uniparc2af[uniparc] = afname
    with open(outfile, 'wb') as f:
        pickle.dump(uniparc2af, f)


def init_indiv_pkls(data, pklfiles):
    for uniparc, chain_pairs in data.items():
        pklfile = [yf for yf in pklfiles if uniparc in yf]
        if len(pklfile) != 1:
            raise ValueError(f'should find exactly one matching pkl filename for uniparc {uniparc} but found {len(pklfile)}')
        pklfile = pklfile[0]
        if os.path.exists(pklfile):
            continue
        unit_data = {
            uniparc: chain_pairs
        }
        with open(pklfile, 'wb') as f:
            pickle.dump(unit_data, f)


def write_yes_if_func(outfile, func, *args):
    if func(*args):
        simple_write(outfile, 'yes')
    



def match_seq_to_afdb(query_fasta, afdb_fasta):
    _, target_seq = next(read_prot_from_fasta(input.fasta))
    for header, seq in read_prot_from_fasta(afdb_fasta):
        if seq == target_seq:
            name = re.findall('>AFDB:(.*?)\s', header)[0]
            return name
    return None


def filter_only_contacting_structures(uniparc, inpkl, outpkl):
    with open(inpkl, 'rb') as f:
        data = pickle.load(f)
    dimers = data[uniparc]
    dimers_in_contact = []
    
    lib_path = config['paths']['lib']
    dist_thresh = config['database_settings']['dimer_define_contact_distance_threshold_angstroms']
    count_thresh = config['database_settings']['dimer_define_contact_min_total_contacting_pairs']

    for d in dimers:
        pdb1, pdb2 = dimer2pdbs(d, lib_path)
        if check_chains_contact(pdb1, pdb2, label_funcs, dist_thresh, count_thresh):
            dimers_in_contact.append(d)

    if len(dimers_in_contact) > count_thresh:
        data[uniparc] = dimers_in_contact
        with open(outpkl, 'wb') as f:
            pickle.dump(data, f)



##########################################
############## HOMODIMER RULES ###########
# VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV #

localrules: download_xray_resolu

rule download_xray_resolu:
    output:
        resolu = config['paths']['resolu_file']
    shell:
        '''
        wget -O {output.resolu} https://files.wwpdb.org/pub/pdb/derived_data/index/resolu.idx;
        '''


rule init_indiv_pkls_homo: 
    output:
        pklfiles = expand(out_base_path_homo+'/{div}/{sample}/initial.pkl', zip, div=divs, sample=samples_homo)
    threads: 1
    resources:
       time = "48:00:00",
       mem_mb = "30000"
    run:
        init_indiv_pkls(data=homodimers_data, pklfiles=output.pklfiles)






rule prefilter_by_in_afdb_homo:
    input:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/initial.pkl'
    output:
        info = out_base_path_homo+'/{div}/{sample}/ok_afdb.info'
    threads: 1
    resources:
        mem_mb = "8000"
    run:
        simple_write(output.info, 'no')
        afdb_fasta = config['paths']['afdb_fasta']
        af_name = match_seq_to_afdb(input.fasta, afdb_fasta)
        if af_name:
            simple_write(output.info, f'{af_name}')


                    
                    

rule prefilter_by_physical_contact:
    input:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/initial.pkl',
        info = out_base_path_homo+'/{div}/{sample_homo}/ok_afdb.info'
    output:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/incontact.pkl'
    threads: 1
    resources:
        mem_mb = "8000",
        time = "4:00:00"
    run:
        simple_write(output.pklfile, '')
        with open(input.info, 'r') as f:
             afdb_ok = f.read().strip() != 'no'
        if afdb_ok:
            filter_only_contacting_structures(uniparc=wildcards.sample_homo, inpkl=input.pklfile, outpkl=output.pklfile)




rule filter_by_redundancy:
    input:
        resolu = config['paths']['resolu_file'],
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/incontact.pkl'
    output:
        pklfile = out_base_path_homo+'/{div}/{sample_homo}/incontact_nonredundant.pkl'
    threads: 4
    resources:
        mem_mb = 5000,
        time = "4:00:00"
    run:
        simple_write(output.pklfile, '')
        with open(input.pklfile, 'r') as f:
            loaded = pkl.safe_load()
        if loaded: 
            uniparc = loaded.keys()[0]
            structures = loaded[uniparc] 
            dimers = RedundantDimerStructures(dimer_tuples=structures, threshold=config['database_settings']['dimer_cluster_distance_threshold'], config=config)
            non_redundant_dimers = {}
            non_redundant_dimers[uniparc] = dimers.prune_redundancy(num_workers=threads)
            with open(output.pklfile, 'wb') as f:
                pickle.dump(non_redundant_dimers, f)





rule merge_homo_data:
    input:
        pklfiles = expand(out_base_path_homo+'/{div}/{sample}/incontact_nonredundant.pkl', zip, div=divs, sample=samples_homo),
        afinfos = expand(out_base_path_homo+'/{div}/{sample}/ok_afdb.info', zip, div=divs, sample=samples_homo)
    output:
        merged_pklfile = config['intermediate_data_files']['sub2_homo_prefiltered_pkl'],
        merged_uniparc2af = config['intermediate_data_files']['sub2_uniparc2af_pkl_homo']
    threads: 1
    resources:
        mem_mb = 5000,
        time = '24:00:00'
    run:
        merge_pklfiles(infiles=input.pklfiles, outfile=output.merged_pklfile)
        make_uniparc2afinfo(afinfo_files=input.afinfos, names=samples_homo, outfile=output.merged_uniparc2af)


