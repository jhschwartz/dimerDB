import os
import sys
import requests
import pickle
from sortedcontainers import SortedSet

configfile: 'config.yaml'

sys.path.append(config['paths']['scripts'])
from simple_write import simple_write
from download_uniparc_fasta import download_fasta 
from name_fasta import uniparc_fasta




python = config['runtime']['python']

id_mapping_fn = config['intermediate_data_files']['sub1_id_mapping_fn']

# force id_mapping update
if config['database_settings']['force_update_id_mapping'] and os.path.exists(id_mapping):
    os.remove(id_mapping)



def get_id_mapping():
    # avoid redownloading 
    if not os.path.exists(id_mapping_fn):
        shell('''
            wget -O {id_mapping_fn} ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/idmapping_selected.tab.gz;
        ''')
    else:
        shell(''' touch {id_mapping_fn} ''')


localrules: all, retrieve_id_mapping_file, spotcheck_uniparc2others, spotcheck_homodimers 

rule all:
    input: 
        config['intermediate_data_files']['sub1_all_homodimers_pkl'],
        config['snake_donefiles']['sub1_homodimers_checked_done']
    output:
        done = config['snake_donefiles']['sub1_all_done']
    run:
        simple_write(output.done, 'success')




rule retrieve_id_mapping_file:
    output:
        filename = id_mapping_fn
    run:
        get_id_mapping()



rule create_uniparc_to_others:
    input:
        id_mapping = id_mapping_fn
    output:
        uniparc2others = config['intermediate_data_files']['sub1_uniparc2others_pkl'],
        uniparc_index = config['intermediate_data_files']['sub1_uniparc2others_index']
    threads: 1
    resources:
        time = "12:00:00",
        mem_mb = "10000"
    run:
        from scripts.uniparc_to_uniprot_and_pdb import make_uniparc2others
        uniparc2others_data = make_uniparc2others(infile=input.id_mapping, outfile=output.uniparc2others)
        uniparc_names = SortedSet(uniparc2others_data.keys())
        with open(output.uniparc_index, 'wb') as f:
            pickle.dump(uniparc_names, f)



rule spotcheck_uniparc2others:
    input:
        pklfile = config['intermediate_data_files']['sub1_uniparc2others_pkl']
    output:
        passed = config['snake_donefiles']['sub1_uniparc2others_checked_done']
    threads: 1
    run:
        from spotcheck_subflow1_pkls import check_uniparc2others
        check_uniparc2others(input.pklfile)
        simple_write(output.passed, 'success')


rule download_uniparc_seqs:
    input:
        indexfile = config['intermediate_data_files']['sub1_uniparc2others_index']
    output:
        done = config['snake_donefiles']['sub1_uniparc_download_done']
    params:
        seqs_dir = config['paths']['uniparc_seqs']
    resources:
        time = "12:00:00",
        mem_mb = "10000"
    run:
        seqs_downloaded = SortedSet()
        for root, dirs, files in os.walk(params.seqs_dir):
            for f in files:
                if f.endswith('.fasta'):
                    seqs_downloaded.add(f)

        with open(input.indexfile, 'rb') as f:
            uniparc_ids = pickle.load(f)
        for uniparc in uniparc_ids:
            if uniparc in seqs_downloaded:
                continue
            fasta = uniparc_fasta(uniparc_id=uniparc, lib_path=config['paths']['lib'])
            download_fasta(uniparc, fasta)
        simple_write(output.done, 'success')
          

rule expand_clean_uniparc2others:
    input:
        pklfile = config['intermediate_data_files']['sub1_uniparc2others_pkl'],
        download_uniparcs_done = config['snake_donefiles']['sub1_uniparc_download_done']
    output:
        pklfile = config['intermediate_data_files']['sub1_uniparc2others_expanded_cleaned_pkl']
    resources:
        time = "12:00:00",
        mem_mb = "10000"
    run:
        from scripts.expand_clean_uniparc2others import expand_clean_uniparc2others
        expand_clean_uniparc2others(inpkl=input.pklfile, outpkl=output.pklfile, config=config)



rule derive_all_homodimers:
    input:
        uniparc2others = config['intermediate_data_files']['sub1_uniparc2others_expanded_cleaned_pkl'],
        uniparc2others_checked = config['snake_donefiles']['sub1_uniparc2others_checked_done'],
        download_uniparcs_done = config['snake_donefiles']['sub1_uniparc_download_done']
    output:
        homodimers = config['intermediate_data_files']['sub1_all_homodimers_pkl']
    threads: 1
    resources:
        time = "4:00:00",
        mem_mb = "5000"
    run:
        from scripts.derive_all_possible_homodimers import derive_homodimers
        derive_homodimers(input.uniparc2others, output.homodimers, config)




rule spotcheck_homodimers:
    input:
        pklfile = config['intermediate_data_files']['sub1_all_homodimers_pkl']
    output:
        passed = config['snake_donefiles']['sub1_homodimers_checked_done']
    threads: 1
    run:
        from spotcheck_subflow1_pkls import check_homodimers
        check_homodimers(input.pklfile)
        simple_write(output.passed, 'success')


