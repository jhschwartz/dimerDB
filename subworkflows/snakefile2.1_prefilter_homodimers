import sys
import os
import yaml

configfn = 'config.yaml'  
configfile: configfn


sys.path.append(config['paths']['scripts'])
from simple_write import simple_write
from download_uniparc_fasta import download_fasta
from read_fasta import read_prot_from_fasta
from name_pdb import dimer2pdbs
from check_chains_contact import check_chains_contact

sys.path.append(config['paths']['scripts'])
from name_pdb import name_pdb_file

sys.path.append(config['paths']['labels_loc'])
import labels as label_funcs





out_base_dir = config['paths']['intermediates_homodimer_filtering']

homodimers_yaml = config['snake_data_yaml_files']['sub1_all_homodimers_yaml']
uniparc2others_yaml = config['snake_data_yaml_files']['sub1_uniparc2others_yaml']

# TEMP for quick testing
#homodimers_yaml = '/nfs/turbo/umms-petefred/jaschwa/dimerDB/intermediates/fake_all_homodimers.yaml'
#uniparc2others_yaml = '/nfs/turbo/umms-petefred/jaschwa/dimerDB/intermediates/fake_uniparc2others.yaml'

with open(homodimers_yaml, 'r') as f:
    homodimers_data = yaml.safe_load(f)
    samples = homodimers_data.keys()

divs = [s[-2:] for s in samples]


with open(uniparc2others_yaml, 'r') as f:
    uniparc2others = yaml.safe_load(f)




# len -> afdb -> contact 

rule all:
    input:
        dimers = expand(out_base_dir+'/{div}/{sample}/filtered.yaml', zip, div=divs, sample=samples),
        afs = expand(out_base_dir+'/{div}/{sample}/ok_len_afdb.info', zip, div=divs, sample=samples)
    output:
        merged_dimers = config['snake_data_yaml_files']['sub2_homo_prefiltered_yaml'],
        merged_uniparc2af = config['snake_data_yaml_files']['sub2_uniparc2af_yaml'],
        done = config['snake_donefiles']['sub2_all_done']
    threads: 1
    resources:
        mem_mb = 5000,
        time = '12:00:00'
    run:
        data = {}
        for yamlfile in input.dimers:    
            with open(yamlfile, 'r') as f:
                data = {**data, **yaml.safe_load(f)} # merge dicts data and the read dict from yaml
        with open(output.merged_dimers, 'w') as f:
            yaml.dump(data, f, default_flow_style=None)
        
        uniparc2af = {}
        for afinfo, uniparc in zip(input.afs, samples):
            with open(afinfo, 'r') as f:
                info = f.read()
                if 'yes' in info:
                    afname = info.split()[1]
                    uniparc2af[uniparc] = afname
        with open(output.merged_uniparc2af, 'w') as f:
            yaml.dump(uniparc2af, f, default_flow_style=None)

        simple_write(output.done, 'success')


rule init_indiv_yamls:
    output:
        yamlfiles = expand(out_base_dir+'/{div}/{sample}/initial.yaml', zip, div=divs, sample=samples)
    threads: 1
    resources:
       time = "48:00:00",
       mem_mb = "30000"
    run:
        for uniparc, chain_pairs in homodimers_data.items():
            yamlfile = [yf for yf in output.yamlfiles if uniparc in yf]
            if len(yamlfile) != 1:
                raise ValueError(f'should only find one matching yaml filename for uniparc {uniparc}')
            yamlfile = yamlfile[0]
            if os.path.exists(yamlfile):
                continue
            data = {
                uniparc: chain_pairs
            }
            with open(yamlfile, 'w') as f:
                yaml.dump(data, f, default_flow_style=None)



rule prefilter_by_length:
    input:
        yamlfile = out_base_dir+'/{div}/{sample}/initial.yaml'
    output:
        info = out_base_dir+'/{div}/{sample}/ok_len.info',
        fasta = out_base_dir+'/{div}/{sample}/seq.fasta'
    threads: 1
    resources:
        mem_mb = "8000"
    run:
        simple_write(output.info, 'no')
        download_fasta(wildcards.sample, output.fasta)
        _, seq = next(read_prot_from_fasta(output.fasta))
        if len(seq) <= 0:
            raise ValueError(f'failed to download and read seq for {wildcards.sample}')
        if len(seq) <= config['database_settings']['chain_max_seq_len']:
            simple_write(output.info, 'yes')


rule prefilter_by_in_afdb:
    input:
        info = out_base_dir+'/{div}/{sample}/ok_len.info',
        fasta = out_base_dir+'/{div}/{sample}/seq.fasta'
    output:
        info = out_base_dir+'/{div}/{sample}/ok_len_afdb.info'
    threads: 1
    resources:
        mem_mb = "8000"
    run:
        simple_write(output.info, 'no')
        with open(input.info, 'r') as f:
            len_ok = 'yes' in f.read()
        if len_ok:
            afdb_fasta = config['paths']['afdb_fasta']
            _, target_seq = next(read_prot_from_fasta(input.fasta))
            for header, seq in read_prot_from_fasta(afdb_fasta):
                if seq == target_seq:
                    name = re.findall('>AFDB:(.*?)\s', header)[0]
                    simple_write(output.info, f'yes, {name}')
                    
                    


rule prefilter_by_physical_contact:
    input:
        yamlfile = out_base_dir+'/{div}/{sample}/initial.yaml',
        info = out_base_dir+'/{div}/{sample}/ok_len_afdb.info'
    output:
        yamlfile = out_base_dir+'/{div}/{sample}/filtered.yaml'
    threads: 1
    resources:
        mem_mb = "8000",
        time = "4:00:00"
    run:
        simple_write(output.yamlfile, '')
        with open(input.info, 'r') as f:
            len_afdb_ok = 'yes' in f.read()
        if len_afdb_ok:
            with open(input.yamlfile, 'r') as f:
                data = yaml.safe_load(f)
            dimers = data[wildcards.sample]
            dimers_in_contact = []
            for d in dimers:
                pdb_base_dir = config['paths']['rcsb']
                dist_thresh = config['database_settings']['dimer_define_contact_distance_threshold_angstroms']
                count_thresh = config['database_settings']['dimer_define_contact_min_total_contacting_pairs']
                pdb1, pdb2 = dimer2pdbs(d, pdb_base_dir)
                if check_chains_contact(pdb1, pdb2, label_funcs, dist_thresh, count_thresh):
                    dimers_in_contact.append(d)

            if len(dimers_in_contact) > 0:
                data[wildcards.sample] = dimers_in_contact
                with open(output.yamlfile, 'w') as f:
                    yaml.dump(data, f, default_flow_style=None)









